{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "75923006",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datasets\n",
    "import elfen\n",
    "import polars as pl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0b5c7afa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (5, 3)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>idx</th><th>sentence</th><th>label</th></tr><tr><td>i32</td><td>str</td><td>i64</td></tr></thead><tbody><tr><td>0</td><td>&quot;uneasy mishmash of styles and …</td><td>-1</td></tr><tr><td>1</td><td>&quot;this film &#x27;s relationship to a…</td><td>-1</td></tr><tr><td>2</td><td>&quot;by the end of no such thing th…</td><td>-1</td></tr><tr><td>3</td><td>&quot;director rob marshall went out…</td><td>-1</td></tr><tr><td>4</td><td>&quot;lathan and diggs have consider…</td><td>-1</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (5, 3)\n",
       "┌─────┬─────────────────────────────────┬───────┐\n",
       "│ idx ┆ sentence                        ┆ label │\n",
       "│ --- ┆ ---                             ┆ ---   │\n",
       "│ i32 ┆ str                             ┆ i64   │\n",
       "╞═════╪═════════════════════════════════╪═══════╡\n",
       "│ 0   ┆ uneasy mishmash of styles and … ┆ -1    │\n",
       "│ 1   ┆ this film 's relationship to a… ┆ -1    │\n",
       "│ 2   ┆ by the end of no such thing th… ┆ -1    │\n",
       "│ 3   ┆ director rob marshall went out… ┆ -1    │\n",
       "│ 4   ┆ lathan and diggs have consider… ┆ -1    │\n",
       "└─────┴─────────────────────────────────┴───────┘"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds = datasets.load_dataset(\"stanfordnlp/sst2\")\n",
    "df_test = pl.from_pandas(ds[\"test\"].to_pandas())[:100]\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "67ca754e",
   "metadata": {},
   "outputs": [],
   "source": [
    "extractor = elfen.Extractor(\n",
    "    data=df_test,\n",
    "    text_column=\"sentence\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a9b515ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 5)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extractor.extract(\"n_tokens\")\n",
    "extractor.data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ff6beb99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (9, 2)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>statistic</th><th>value</th></tr><tr><td>str</td><td>f64</td></tr></thead><tbody><tr><td>&quot;count&quot;</td><td>100.0</td></tr><tr><td>&quot;null_count&quot;</td><td>0.0</td></tr><tr><td>&quot;mean&quot;</td><td>19.99</td></tr><tr><td>&quot;std&quot;</td><td>9.48523</td></tr><tr><td>&quot;min&quot;</td><td>3.0</td></tr><tr><td>&quot;25%&quot;</td><td>13.0</td></tr><tr><td>&quot;50%&quot;</td><td>19.0</td></tr><tr><td>&quot;75%&quot;</td><td>25.0</td></tr><tr><td>&quot;max&quot;</td><td>48.0</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (9, 2)\n",
       "┌────────────┬─────────┐\n",
       "│ statistic  ┆ value   │\n",
       "│ ---        ┆ ---     │\n",
       "│ str        ┆ f64     │\n",
       "╞════════════╪═════════╡\n",
       "│ count      ┆ 100.0   │\n",
       "│ null_count ┆ 0.0     │\n",
       "│ mean       ┆ 19.99   │\n",
       "│ std        ┆ 9.48523 │\n",
       "│ min        ┆ 3.0     │\n",
       "│ 25%        ┆ 13.0    │\n",
       "│ 50%        ┆ 19.0    │\n",
       "│ 75%        ┆ 25.0    │\n",
       "│ max        ┆ 48.0    │\n",
       "└────────────┴─────────┘"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extractor.data[\"n_tokens\"].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "aea7dd6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 19)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extractor.extract_feature_group(\"readability\")\n",
    "extractor.data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c404efaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting raw_sequence_length...\n",
      "Extracting n_tokens...\n",
      "Extracting n_sentences...\n",
      "Extracting n_tokens_per_sentence...\n",
      "Extracting n_characters...\n",
      "Extracting avg_word_length...\n",
      "Extracting n_types...\n",
      "Extracting n_long_words...\n",
      "Extracting n_lemmas...\n",
      "Extracting n_per_morph_feature...\n",
      "Extracting tree_width...\n",
      "Extracting tree_depth...\n",
      "Extracting tree_branching...\n",
      "Extracting n_noun_chunks...\n",
      "Extracting n_per_dependency_type...\n",
      "Extracting sentiment_score...\n",
      "Extracting n_negative_sentiment...\n",
      "Extracting n_positive_sentiment...\n",
      "Extracting avg_valence...\n",
      "Extracting n_low_valence...\n",
      "Extracting n_high_valence...\n",
      "Extracting avg_arousal...\n",
      "Extracting n_low_arousal...\n",
      "Extracting n_high_arousal...\n",
      "Extracting avg_dominance...\n",
      "Extracting n_low_dominance...\n",
      "Extracting n_high_dominance...\n",
      "Extracting avg_emotion_intensity...\n",
      "Extracting n_low_intensity...\n",
      "Extracting n_high_intensity...\n",
      "Extracting compressibility...\n",
      "Extracting entropy...\n",
      "Extracting lemma_token_ratio...\n",
      "Extracting ttr...\n",
      "Extracting rttr...\n",
      "Extracting cttr...\n",
      "Extracting herdan_c...\n",
      "Extracting summer_index...\n",
      "Extracting dugast_u...\n",
      "Extracting maas_index...\n",
      "Extracting lexical_density...\n",
      "Extracting n_hapax_legomena...\n",
      "Extracting n_global_token_hapax_legomena...\n",
      "Extracting n_global_lemma_hapax_legomena...\n",
      "Extracting n_hapax_dislegomena...\n",
      "Extracting n_global_token_hapax_dislegomena...\n",
      "Extracting n_global_lemma_hapax_dislegomena...\n",
      "Extracting sichel_s...\n",
      "Extracting global_sichel_s...\n",
      "Extracting giroud_index...\n",
      "Extracting mtld...\n",
      "Extracting hdd...\n",
      "Extracting mattr...\n",
      "Extracting msttr...\n",
      "Extracting yule_k...\n",
      "Extracting simpsons_d...\n",
      "Extracting herdan_v...\n",
      "Extracting n_lexical_tokens...\n",
      "Extracting pos_variability...\n",
      "Extracting n_per_pos...\n",
      "Extracting avg_concreteness...\n",
      "Extracting n_low_concreteness...\n",
      "Extracting n_high_concreteness...\n",
      "Extracting avg_sd_concreteness...\n",
      "Extracting n_controversial_concreteness...\n",
      "Extracting min_concreteness...\n",
      "Extracting max_concreteness...\n",
      "Extracting avg_aoa...\n",
      "Extracting n_low_aoa...\n",
      "Extracting n_high_aoa...\n",
      "Extracting avg_sd_aoa...\n",
      "Extracting n_controversial_aoa...\n",
      "Extracting min_aoa...\n",
      "Extracting max_aoa...\n",
      "Extracting avg_prevalence...\n",
      "Extracting n_low_prevalence...\n",
      "Extracting n_high_prevalence...\n",
      "Extracting min_prevalence...\n",
      "Extracting max_prevalence...\n",
      "Extracting avg_socialness...\n",
      "Extracting n_low_socialness...\n",
      "Extracting n_high_socialness...\n",
      "Extracting avg_sd_socialness...\n",
      "Extracting n_controversial_socialness...\n",
      "Extracting min_socialness...\n",
      "Extracting max_socialness...\n",
      "Extracting avg_sensorimotor...\n",
      "Extracting n_low_sensorimotor...\n",
      "Extracting n_high_sensorimotor...\n",
      "Extracting avg_sd_sensorimotor...\n",
      "Extracting n_controversial_sensorimotor...\n",
      "Extracting min_sensorimotor...\n",
      "Extracting max_sensorimotor...\n",
      "Extracting avg_iconicity...\n",
      "Extracting n_low_iconicity...\n",
      "Extracting n_high_iconicity...\n",
      "Extracting avg_sd_iconicity...\n",
      "Extracting n_controversial_iconicity...\n",
      "Extracting min_iconicity...\n",
      "Extracting max_iconicity...\n",
      "Extracting n_syllables...\n",
      "Extracting n_monosyllables...\n",
      "Extracting n_polysyllables...\n",
      "Extracting flesch_reading_ease...\n",
      "Extracting flesch_kincaid_grade...\n",
      "Extracting gunning_fog...\n",
      "Extracting ari...\n",
      "Extracting smog...\n",
      "Extracting cli...\n",
      "Extracting lix...\n",
      "Extracting rix...\n",
      "Extracting n_lemmas...\n",
      "Extracting n_hedges...\n",
      "Extracting avg_num_synsets...\n",
      "Extracting avg_num_synsets_per_pos...\n",
      "Extracting n_low_synsets...\n",
      "Extracting n_high_synsets...\n",
      "Extracting n_high_synsets_per_pos...\n",
      "Extracting n_low_synsets_per_pos...\n",
      "Extracting n_entities...\n",
      "Extracting n_per_entity_type...\n"
     ]
    }
   ],
   "source": [
    "extractor.extract_features()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "523172a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 1107)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extractor.data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4df8af4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "elfen-examples",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
